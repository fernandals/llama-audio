> initializing model parallel with size 1
> initializing ddp with size 1
> initializing pipeline with size 1
/home/fkldsilva/.conda/envs/tts/lib/python3.12/site-packages/torch/__init__.py:690: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
Loaded in 99.02 seconds
[tensor([[[568, 568, 568,  ..., 568, 568, 568],
         [804, 804, 804,  ..., 804, 804, 804],
         [ 10,  10,  10,  ...,  10,  10,  10],
         ...,
         [568, 568, 568,  ..., 568, 568, 568],
         [378, 378, 378,  ..., 378, 378, 378],
         [731, 731, 731,  ..., 731, 731, 731]]], device='cpu')]
/mnt/beegfs/scratch/fkldsilva/llama2-audio/llama/generation.py:170: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tokens[k, : len(t)] = torch.tensor(t, dtype=torch.long, device="cuda")
Traceback (most recent call last):
  File "/mnt/beegfs/scratch/fkldsilva/llama2-audio/audio_inference.py", line 77, in <module>
    fire.Fire(main)
  File "/home/fkldsilva/.conda/envs/tts/lib/python3.12/site-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fkldsilva/.conda/envs/tts/lib/python3.12/site-packages/fire/core.py", line 475, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/home/fkldsilva/.conda/envs/tts/lib/python3.12/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/beegfs/scratch/fkldsilva/llama2-audio/audio_inference.py", line 64, in main
    results = generator.text_completion(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/beegfs/scratch/fkldsilva/llama2-audio/llama/generation.py", line 267, in text_completion
    generation_tokens, generation_logprobs = self.generate(
                                             ^^^^^^^^^^^^^^
  File "/home/fkldsilva/.conda/envs/tts/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/beegfs/scratch/fkldsilva/llama2-audio/llama/generation.py", line 170, in generate
    tokens[k, : len(t)] = torch.tensor(t, dtype=torch.long, device="cuda")
    ~~~~~~^^^^^^^^^^^^^
RuntimeError: expand(torch.cuda.LongTensor{[9, 832]}, size=[1]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)
[2024-03-28 10:20:25,598] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 1922535) of binary: /home/fkldsilva/.conda/envs/tts/bin/python
Traceback (most recent call last):
  File "/home/fkldsilva/.conda/envs/tts/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/fkldsilva/.conda/envs/tts/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/fkldsilva/.conda/envs/tts/lib/python3.12/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/fkldsilva/.conda/envs/tts/lib/python3.12/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/fkldsilva/.conda/envs/tts/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fkldsilva/.conda/envs/tts/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
audio_inference.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-03-28_10:20:25
  host      : gpunode2.localdomain
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1922535)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
